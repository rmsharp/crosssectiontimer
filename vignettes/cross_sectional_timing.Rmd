---
title: "Test of a Cross-sectional Sampling Timer"
author: "R. Mark Sharp"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2: default
  bookdown::html_document2: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.pos = 'H')
library("crosssectiontimer")
library(ggplot2)
library(kableExtra)
library(magrittr)
library(rmsutilityr)
library(stringi)

```

# Purpose

We want to gain insight into how much time is spent on specific activities by 
various actors^[business partners, developers, implementers, Modeling
Center of Excellence (MCOE) personnel, and Model Risk Management (MRM) personnel]
responsible for the success of the model deployment life-cycle.
It is anticipated that having time on task data will provide insight in those
areas where where improvement opportunities exist.

Detailed planning regarding questions to be addressed is required to design
which activities^[We expect that well over 
20 percent of time is used in activities that are not directly related to 
model deployment or use. Planning how much detail to collect and how the data
will be analyzed should occur prior to any data being collected.]
should be measured. 
However, the intent of this document is to
propose the use of a cross-sectional study design instead of longitudinal 
design.

A benefit of time on task studies is that they provide hard data regarding how 
time is spent and how much of it directly contributes to our primary goals.
A second benefit is that these data
allow each class of actor to advocate for modifying the way their
time is being used to improve their work environment and productivity.

A longitudinal design calls for representative actors within each group to
log defined activities during their work day.
Logging of time on task is has the problems listed below.   

-   Failure rate in logging activities can be high.
-   Recall of the amount of time spent is often wrong.
-   Preconceptions of how time should be spent biases recalled durations.
-   Keeping, collecting, and analyzing logs requires significant administrative
    overhead to an already administrative heavy environment.
-   The biases introduced from earlier points makes interpretation of results
    difficult.
-   The longitudinal collection of data requires a long data collection
    phase before any analysis can begin. 
-   Variance among different projects is anticipated to be high, which
    further complicates analysis.

The cross-sectional design assumes that we have the ability to send a question
to selected individuals and collect that response.

The cross-sectional design presented and tested below has the following
advantages.

-   Failure rate has far less impact since failure to respond simply 
    initiates another response request.
-   Participants do not need to recall time spent.
-   Administrative overhead is greatly reduced.
-   Bias is minimized.
-   Data could be analyzed within the first month of use.
-   Variance among projects could be assessed and more accurately measured if
    desired. However, I recommend that project differences be ignored
    at the outset.


# Scenario

The remainder of this document presents a simple simulation study using a
realistic design 
and provides sufficient detail to assess expected data quality.

The simulated model has a set of representative activities for developers.^[
The software is has the ability to examine multiple job types, job specific
activity lists, and corresponding expected frequencies.]. 
It simulates asking a set of developers to indicate
which of the activities listed on the questionnaire they were doing at the time
the question popped up on their screen. Once the developer makes a selection,
that selection is returned as a result to the collection software, which
cumulates the responses for later analysis. 

In the simulation model, these queries and responses can all be processed in
less than a second but as described below this simulation is constructed so that
each simulated developer responds only five times during the entire
duration of the experiments illustrated below.

The manner in which the questions are presented and the timing of when the 
questions are presented are critical aspects of the study design, which are 
not discusses further.

## Simulation

The developers' activities are programmed to occur with the following 
frequencies.

```{r activities, echo = TRUE}
dev_freq <- c(
  0.05, # data discovery
  0.10, # data analysis 
  0.05, # data marshaling 
  0.05, # data transformation 
  0.05, # model selection 
  0.15, # model training 
  0.20, # model testing 
  0.05, # output coding 
  0.01, # metric coding 
  0.01, # ongoing monitoring coding 
  0.03, # literature research 
  0.03, # communication with implementors 
  0.02, # communication with business partners 
  0.01, # peer review 
  0.01, # narrative writing 
  0.02, # model description formatting 
  0.01, # ongoing monitoring report formatting, # model description
  0.10, # administrative tasks, not directly related to modeling; including
        # general training, communications, etc.
  0.01, # training related to modeling
  0.02, # personal activities that are not work related
  0.02) # other

```

For clarity, we demonstrate one and three samples.

A single sample: `r make_activity_observation("developer", size = 1, dev_freq)`   
Three samples: `r get_and_or_list(make_activity_observation("developer", size = 3, dev_freq))`.

Lets see how precise our estimates would be if we included 20 developers 
sampled just 5 times a month for each of 12 months.

Since the algorithm is not actually modeling individual developers, the order of 
sampling has no impact on results, which means we simply take `r 20*5*12` 
(20 * 5 * 12) compare each result set to the expected values.

```{r small-sample,}
activities <- get_defined_activities()
dev_activities <- activities[activities$actor_type == "developer", 
                             c("action", "description")]
dev_activities <- cbind(dev_activities, prob = dev_freq)
small_sample <- make_activity_observation("developer", size = 20 * 5 * 12, 
                                          dev_freq)
small_sample_counts <- table(small_sample)
sample_size <- sum(small_sample_counts)
small_sample_duration <- small_sample_counts / sample_size

small_sample_duration <- 
  make_complete_sample_durations(small_sample_duration, dev_activities)

dev_activities <- dev_activities[order(dev_activities$action), ]

caption <- stri_c("List of activities, the frequency in which they were ",
                  "observed, the simulated frequency of the activity ",
                  "(expected), and the absolute difference between the ",
                  "observed and expected frequencies.")

delta <- abs(small_sample_duration$duration - dev_activities$prob)
small_sample_duration %>%
  cbind(data.frame(prob = dev_activities$prob, delta = delta)) %>%
  kbl(digits = 3, 
      col.names = c("Description", "Observed", "Expected", "Delta"),
      caption = caption) %>%
  kable_styling(latex_options = "HOLD_position") %>%
  add_header_above(c(" " = 1, "Duration" = 3)) %>%
  kable_material(c("striped", "hover")) 

```


We can estimate the duration in minutes on each activity if we allocate 
the `r 20 * 5 * 12` observations into one 8 hour day which has 560 minutes.

```{r small-sample-in-minutes}
minutes_per_activity <- small_sample_duration$duration * 560
minutes_per_activity <- data.frame(description = small_sample_duration$description,
                                    minutes = as.numeric(minutes_per_activity))
caption <- stri_c("List of activities and the estimated number of minutes ",
                  "spent on the activity if represented in a single day.")
minutes_per_activity %>%
  kbl(digits = 1, col.names = c("Description", "Minutes"),
      caption = caption) %>%
  kable_styling(latex_options = "HOLD_position") %>%
  kable_material(c("striped", "hover"))

```

I have run this experiment several times and usually the 
estimates are shown to be very close as in seen in the _Delta_ column
(within about 1 percent). However, it is more instructive to simulation this 
experiment many times to learn what precision we can expect.

<!-- We will start by putting the simulation into a function. Note that this is 
not a generic function as it assumes the presence of the globally defined 
objects (__dev_prop__ and __dev_activities__) and it knows about their 
structure.
-->

```{r simulation-function, echo = FALSE}
sim_sample_duration <- function(size = 20 * 5 * 12, iterations = 1) {
  max_delta <- numeric(iterations)
  for (i in seq_len(iterations)) {
    small_sample <-
      make_activity_observation("developer", size = size,
                                dev_freq)
    small_sample_counts <- table(small_sample)
    sample_size <- sum(small_sample_counts)
    small_sample_duration <- small_sample_counts / sample_size
    max_delta[i] <- max(abs(small_sample_duration - dev_activities$prob))
  }
  max_delta
}

```

Figure \@ref(fig:hist-1200) shows a histogram plot of 
the results of 
repeating the simulation of 20 developers providing 5 responses 
in each of the 12 months of a year 1000 times. 
Similarly, Figure \@ref(fig:hist-2400) shows a histogram plot of 
the similar simulation with 40 developers instead of 20.

```{r hist-1200, fig.cap="20 developers sampled 5 times per month for one year"}
iterations <- 10000
n_developers <- 20
sim_delta_freq <- sim_sample_duration(size = n_developers * 5 * 12, 
                                         iterations = iterations)
gt_2_percent <- sum(sim_delta_freq > 0.02) / length(sim_delta_freq)
gt_3_percent <- sum(sim_delta_freq > 0.03) / length(sim_delta_freq)

data.frame(freq = sim_delta_freq) %>%
ggplot(aes(x = freq)) + 
  geom_histogram(bins = 30) +
  ggtitle(stri_c("Simulation of ", iterations, " iterations with ",
                 n_developers, " developers found ", 
                 100 * gt_2_percent, "% of durations \nwere greater than ", 
                 "2 percent away from the ",
                 "expected value and ", 100 * gt_3_percent, 
                 "% of \ndurations were greater than 3 ", 
                 "percent away from the expected value.")) +
  xlab("Absolute Value of (Expected - Observed) Frequency") +
  ylab("Count")

```

What if we double our sample size for each iteration?

```{r hist-2400, fig.cap="40 developers sampled 5 times per month for one year"}
iterations <- 10000
n_developers <- 40
sim_delta_freq <- sim_sample_duration(size = n_developers * 5 * 12, 
                                         iterations = iterations)
gt_2_percent <- sum(sim_delta_freq > 0.02) / length(sim_delta_freq)
gt_3_percent <- sum(sim_delta_freq > 0.03) / length(sim_delta_freq)

data.frame(freq = sim_delta_freq) %>%
ggplot(aes(x = freq)) + 
  geom_histogram(bins = 30) +
  ggtitle(stri_c("Simulation of ", iterations, " iterations with ",
                 n_developers, " developers found ", 
                 100 * gt_2_percent, "% of durations \nwere greater than ", 
                 "2 percent away from the ",
                 "expected value and ", 100 * gt_3_percent, 
                 "% of \ndurations were greater than 3 ", 
                 "percent away from the expected value.")) +
  xlab("Absolute Value of (Expected - Observed) Frequency") +
  ylab("Count") 

```

